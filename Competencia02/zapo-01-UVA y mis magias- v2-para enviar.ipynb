{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Wokflow  **TEST** con Full Bayesiana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:11:42 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 667439</td><td>35.7</td><td>1454584</td><td>77.7</td><td>1139342</td><td>60.9</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1243128</td><td> 9.5</td><td>8388608</td><td>64.0</td><td>1975165</td><td>15.1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  667439 & 35.7 & 1454584 & 77.7 & 1139342 & 60.9\\\\\n",
       "\tVcells & 1243128 &  9.5 & 8388608 & 64.0 & 1975165 & 15.1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  667439 | 35.7 | 1454584 | 77.7 | 1139342 | 60.9 |\n",
       "| Vcells | 1243128 |  9.5 | 8388608 | 64.0 | 1975165 | 15.1 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  667439 35.7 1454584    77.7 1139342  60.9\n",
       "Vcells 1243128  9.5 8388608    64.0 1975165  15.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "Sys.time()\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plocal <- list()\n",
    "\n",
    "# 504\n",
    "plocal$qcanaritos <- 5L\n",
    "plocal$min_data_in_leaf <- 200L\n",
    "plocal$learning_rate <- 1.0\n",
    "plocal$gradient_bound <- 0.4\n",
    "\n",
    "plocal$APO <- 1\n",
    "plocal$ksemillerio <- 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- \"zapo-01-UVA-sinrank+MISMAGIAS-v02-paraenviar\"\n",
    "PARAM$semilla_primigenia <- 202021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create('/content/buckets/b1/exp/competencia02/zlgbm/PARAENVIAR/', showWarnings = FALSE)\n",
    "setwd(\"/content/buckets/b1/exp/competencia02/zlgbm/PARAENVIAR/\")\n",
    "experimento_folder <- PARAM$experimento\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/competencia02/zlgbm/PARAENVIAR/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "### Generacion de la clase_ternaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P863YZB9R1Ua"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:11:43 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>   767483</td><td>  41.0</td><td>   1454584</td><td>  77.7</td><td>  1454584</td><td>  77.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>722145210</td><td>5509.6</td><td>1017395789</td><td>7762.2</td><td>845997410</td><td>6454.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &    767483 &   41.0 &    1454584 &   77.7 &   1454584 &   77.7\\\\\n",
       "\tVcells & 722145210 & 5509.6 & 1017395789 & 7762.2 & 845997410 & 6454.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |    767483 |   41.0 |    1454584 |   77.7 |   1454584 |   77.7 |\n",
       "| Vcells | 722145210 | 5509.6 | 1017395789 | 7762.2 | 845997410 | 6454.5 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)   gc trigger (Mb)   max used  (Mb)  \n",
       "Ncells    767483   41.0    1454584   77.7   1454584   77.7\n",
       "Vcells 722145210 5509.6 1017395789 7762.2 845997410 6454.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:12:14 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()\n",
    "require( \"data.table\" )\n",
    "\n",
    "# leo el dataset\n",
    "dataset <- fread(\"~/datasets/competencia_02_crudo.csv.gz\" )\n",
    "\n",
    "# calculo el periodo0 consecutivo\n",
    "dsimple <- dataset[, list(\n",
    "  \"pos\" = .I,\n",
    "  numero_de_cliente,\n",
    "  periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 )\n",
    "]\n",
    "\n",
    "\n",
    "# ordeno\n",
    "setorder( dsimple, numero_de_cliente, periodo0 )\n",
    "\n",
    "# calculo topes\n",
    "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
    "periodo_anteultimo <- periodo_ultimo - 1\n",
    "\n",
    "\n",
    "# calculo los leads de orden 1 y 2\n",
    "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
    "  shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente\n",
    "]\n",
    "\n",
    "# assign most common class values = \"CONTINUA\"\n",
    "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
    "\n",
    "# calculo BAJA+1\n",
    "dsimple[ periodo0 < periodo_ultimo &\n",
    "  ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
    "  clase_ternaria := \"BAJA+1\"\n",
    "]\n",
    "\n",
    "# calculo BAJA+2\n",
    "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
    "  & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
    "  clase_ternaria := \"BAJA+2\"\n",
    "]\n",
    "\n",
    "# pego el resultado en el dataset original y grabo\n",
    "setorder( dsimple, pos )\n",
    "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
    "\n",
    "rm(dsimple)\n",
    "gc()\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 93 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>foto_mes</th><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>201901</td><td>BAJA+1  </td><td>   645</td></tr>\n",
       "\t<tr><td>201901</td><td>BAJA+2  </td><td>   729</td></tr>\n",
       "\t<tr><td>201901</td><td>CONTINUA</td><td>122899</td></tr>\n",
       "\t<tr><td>201902</td><td>BAJA+1  </td><td>   733</td></tr>\n",
       "\t<tr><td>201902</td><td>BAJA+2  </td><td>   707</td></tr>\n",
       "\t<tr><td>201902</td><td>CONTINUA</td><td>123961</td></tr>\n",
       "\t<tr><td>201903</td><td>BAJA+1  </td><td>   708</td></tr>\n",
       "\t<tr><td>201903</td><td>BAJA+2  </td><td>   751</td></tr>\n",
       "\t<tr><td>201903</td><td>CONTINUA</td><td>124508</td></tr>\n",
       "\t<tr><td>201904</td><td>BAJA+1  </td><td>   756</td></tr>\n",
       "\t<tr><td>201904</td><td>BAJA+2  </td><td>   514</td></tr>\n",
       "\t<tr><td>201904</td><td>CONTINUA</td><td>125268</td></tr>\n",
       "\t<tr><td>201905</td><td>BAJA+1  </td><td>   517</td></tr>\n",
       "\t<tr><td>201905</td><td>BAJA+2  </td><td>   692</td></tr>\n",
       "\t<tr><td>201905</td><td>CONTINUA</td><td>125993</td></tr>\n",
       "\t<tr><td>201906</td><td>BAJA+1  </td><td>   696</td></tr>\n",
       "\t<tr><td>201906</td><td>BAJA+2  </td><td>   608</td></tr>\n",
       "\t<tr><td>201906</td><td>CONTINUA</td><td>127430</td></tr>\n",
       "\t<tr><td>201907</td><td>BAJA+1  </td><td>   611</td></tr>\n",
       "\t<tr><td>201907</td><td>BAJA+2  </td><td>   680</td></tr>\n",
       "\t<tr><td>201907</td><td>CONTINUA</td><td>128977</td></tr>\n",
       "\t<tr><td>201908</td><td>BAJA+1  </td><td>   683</td></tr>\n",
       "\t<tr><td>201908</td><td>BAJA+2  </td><td>   577</td></tr>\n",
       "\t<tr><td>201908</td><td>CONTINUA</td><td>130883</td></tr>\n",
       "\t<tr><td>201909</td><td>BAJA+1  </td><td>   581</td></tr>\n",
       "\t<tr><td>201909</td><td>BAJA+2  </td><td>   582</td></tr>\n",
       "\t<tr><td>201909</td><td>CONTINUA</td><td>132594</td></tr>\n",
       "\t<tr><td>201910</td><td>BAJA+1  </td><td>   594</td></tr>\n",
       "\t<tr><td>201910</td><td>BAJA+2  </td><td>   618</td></tr>\n",
       "\t<tr><td>201910</td><td>CONTINUA</td><td>134798</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>202010</td><td>BAJA+1  </td><td>   544</td></tr>\n",
       "\t<tr><td>202010</td><td>BAJA+2  </td><td>   454</td></tr>\n",
       "\t<tr><td>202010</td><td>CONTINUA</td><td>158171</td></tr>\n",
       "\t<tr><td>202011</td><td>BAJA+1  </td><td>   456</td></tr>\n",
       "\t<tr><td>202011</td><td>BAJA+2  </td><td>   616</td></tr>\n",
       "\t<tr><td>202011</td><td>CONTINUA</td><td>159178</td></tr>\n",
       "\t<tr><td>202012</td><td>BAJA+1  </td><td>   622</td></tr>\n",
       "\t<tr><td>202012</td><td>BAJA+2  </td><td>   619</td></tr>\n",
       "\t<tr><td>202012</td><td>CONTINUA</td><td>159756</td></tr>\n",
       "\t<tr><td>202101</td><td>BAJA+1  </td><td>   622</td></tr>\n",
       "\t<tr><td>202101</td><td>BAJA+2  </td><td>   825</td></tr>\n",
       "\t<tr><td>202101</td><td>CONTINUA</td><td>160080</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+1  </td><td>   831</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+2  </td><td>  1032</td></tr>\n",
       "\t<tr><td>202102</td><td>CONTINUA</td><td>160292</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+1  </td><td>  1039</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+2  </td><td>   951</td></tr>\n",
       "\t<tr><td>202103</td><td>CONTINUA</td><td>161119</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+1  </td><td>   955</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+2  </td><td>  1130</td></tr>\n",
       "\t<tr><td>202104</td><td>CONTINUA</td><td>161333</td></tr>\n",
       "\t<tr><td>202105</td><td>BAJA+1  </td><td>  1134</td></tr>\n",
       "\t<tr><td>202105</td><td>BAJA+2  </td><td>   842</td></tr>\n",
       "\t<tr><td>202105</td><td>CONTINUA</td><td>161941</td></tr>\n",
       "\t<tr><td>202106</td><td>BAJA+1  </td><td>   843</td></tr>\n",
       "\t<tr><td>202106</td><td>BAJA+2  </td><td>  1134</td></tr>\n",
       "\t<tr><td>202106</td><td>CONTINUA</td><td>162336</td></tr>\n",
       "\t<tr><td>202107</td><td>NA      </td><td>163459</td></tr>\n",
       "\t<tr><td>202107</td><td>BAJA+1  </td><td>  1137</td></tr>\n",
       "\t<tr><td>202108</td><td>NA      </td><td>164822</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 93 × 3\n",
       "\\begin{tabular}{lll}\n",
       " foto\\_mes & clase\\_ternaria & N\\\\\n",
       " <int> & <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t 201901 & BAJA+1   &    645\\\\\n",
       "\t 201901 & BAJA+2   &    729\\\\\n",
       "\t 201901 & CONTINUA & 122899\\\\\n",
       "\t 201902 & BAJA+1   &    733\\\\\n",
       "\t 201902 & BAJA+2   &    707\\\\\n",
       "\t 201902 & CONTINUA & 123961\\\\\n",
       "\t 201903 & BAJA+1   &    708\\\\\n",
       "\t 201903 & BAJA+2   &    751\\\\\n",
       "\t 201903 & CONTINUA & 124508\\\\\n",
       "\t 201904 & BAJA+1   &    756\\\\\n",
       "\t 201904 & BAJA+2   &    514\\\\\n",
       "\t 201904 & CONTINUA & 125268\\\\\n",
       "\t 201905 & BAJA+1   &    517\\\\\n",
       "\t 201905 & BAJA+2   &    692\\\\\n",
       "\t 201905 & CONTINUA & 125993\\\\\n",
       "\t 201906 & BAJA+1   &    696\\\\\n",
       "\t 201906 & BAJA+2   &    608\\\\\n",
       "\t 201906 & CONTINUA & 127430\\\\\n",
       "\t 201907 & BAJA+1   &    611\\\\\n",
       "\t 201907 & BAJA+2   &    680\\\\\n",
       "\t 201907 & CONTINUA & 128977\\\\\n",
       "\t 201908 & BAJA+1   &    683\\\\\n",
       "\t 201908 & BAJA+2   &    577\\\\\n",
       "\t 201908 & CONTINUA & 130883\\\\\n",
       "\t 201909 & BAJA+1   &    581\\\\\n",
       "\t 201909 & BAJA+2   &    582\\\\\n",
       "\t 201909 & CONTINUA & 132594\\\\\n",
       "\t 201910 & BAJA+1   &    594\\\\\n",
       "\t 201910 & BAJA+2   &    618\\\\\n",
       "\t 201910 & CONTINUA & 134798\\\\\n",
       "\t ⋮ & ⋮ & ⋮\\\\\n",
       "\t 202010 & BAJA+1   &    544\\\\\n",
       "\t 202010 & BAJA+2   &    454\\\\\n",
       "\t 202010 & CONTINUA & 158171\\\\\n",
       "\t 202011 & BAJA+1   &    456\\\\\n",
       "\t 202011 & BAJA+2   &    616\\\\\n",
       "\t 202011 & CONTINUA & 159178\\\\\n",
       "\t 202012 & BAJA+1   &    622\\\\\n",
       "\t 202012 & BAJA+2   &    619\\\\\n",
       "\t 202012 & CONTINUA & 159756\\\\\n",
       "\t 202101 & BAJA+1   &    622\\\\\n",
       "\t 202101 & BAJA+2   &    825\\\\\n",
       "\t 202101 & CONTINUA & 160080\\\\\n",
       "\t 202102 & BAJA+1   &    831\\\\\n",
       "\t 202102 & BAJA+2   &   1032\\\\\n",
       "\t 202102 & CONTINUA & 160292\\\\\n",
       "\t 202103 & BAJA+1   &   1039\\\\\n",
       "\t 202103 & BAJA+2   &    951\\\\\n",
       "\t 202103 & CONTINUA & 161119\\\\\n",
       "\t 202104 & BAJA+1   &    955\\\\\n",
       "\t 202104 & BAJA+2   &   1130\\\\\n",
       "\t 202104 & CONTINUA & 161333\\\\\n",
       "\t 202105 & BAJA+1   &   1134\\\\\n",
       "\t 202105 & BAJA+2   &    842\\\\\n",
       "\t 202105 & CONTINUA & 161941\\\\\n",
       "\t 202106 & BAJA+1   &    843\\\\\n",
       "\t 202106 & BAJA+2   &   1134\\\\\n",
       "\t 202106 & CONTINUA & 162336\\\\\n",
       "\t 202107 & NA       & 163459\\\\\n",
       "\t 202107 & BAJA+1   &   1137\\\\\n",
       "\t 202108 & NA       & 164822\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 93 × 3\n",
       "\n",
       "| foto_mes &lt;int&gt; | clase_ternaria &lt;chr&gt; | N &lt;int&gt; |\n",
       "|---|---|---|\n",
       "| 201901 | BAJA+1   |    645 |\n",
       "| 201901 | BAJA+2   |    729 |\n",
       "| 201901 | CONTINUA | 122899 |\n",
       "| 201902 | BAJA+1   |    733 |\n",
       "| 201902 | BAJA+2   |    707 |\n",
       "| 201902 | CONTINUA | 123961 |\n",
       "| 201903 | BAJA+1   |    708 |\n",
       "| 201903 | BAJA+2   |    751 |\n",
       "| 201903 | CONTINUA | 124508 |\n",
       "| 201904 | BAJA+1   |    756 |\n",
       "| 201904 | BAJA+2   |    514 |\n",
       "| 201904 | CONTINUA | 125268 |\n",
       "| 201905 | BAJA+1   |    517 |\n",
       "| 201905 | BAJA+2   |    692 |\n",
       "| 201905 | CONTINUA | 125993 |\n",
       "| 201906 | BAJA+1   |    696 |\n",
       "| 201906 | BAJA+2   |    608 |\n",
       "| 201906 | CONTINUA | 127430 |\n",
       "| 201907 | BAJA+1   |    611 |\n",
       "| 201907 | BAJA+2   |    680 |\n",
       "| 201907 | CONTINUA | 128977 |\n",
       "| 201908 | BAJA+1   |    683 |\n",
       "| 201908 | BAJA+2   |    577 |\n",
       "| 201908 | CONTINUA | 130883 |\n",
       "| 201909 | BAJA+1   |    581 |\n",
       "| 201909 | BAJA+2   |    582 |\n",
       "| 201909 | CONTINUA | 132594 |\n",
       "| 201910 | BAJA+1   |    594 |\n",
       "| 201910 | BAJA+2   |    618 |\n",
       "| 201910 | CONTINUA | 134798 |\n",
       "| ⋮ | ⋮ | ⋮ |\n",
       "| 202010 | BAJA+1   |    544 |\n",
       "| 202010 | BAJA+2   |    454 |\n",
       "| 202010 | CONTINUA | 158171 |\n",
       "| 202011 | BAJA+1   |    456 |\n",
       "| 202011 | BAJA+2   |    616 |\n",
       "| 202011 | CONTINUA | 159178 |\n",
       "| 202012 | BAJA+1   |    622 |\n",
       "| 202012 | BAJA+2   |    619 |\n",
       "| 202012 | CONTINUA | 159756 |\n",
       "| 202101 | BAJA+1   |    622 |\n",
       "| 202101 | BAJA+2   |    825 |\n",
       "| 202101 | CONTINUA | 160080 |\n",
       "| 202102 | BAJA+1   |    831 |\n",
       "| 202102 | BAJA+2   |   1032 |\n",
       "| 202102 | CONTINUA | 160292 |\n",
       "| 202103 | BAJA+1   |   1039 |\n",
       "| 202103 | BAJA+2   |    951 |\n",
       "| 202103 | CONTINUA | 161119 |\n",
       "| 202104 | BAJA+1   |    955 |\n",
       "| 202104 | BAJA+2   |   1130 |\n",
       "| 202104 | CONTINUA | 161333 |\n",
       "| 202105 | BAJA+1   |   1134 |\n",
       "| 202105 | BAJA+2   |    842 |\n",
       "| 202105 | CONTINUA | 161941 |\n",
       "| 202106 | BAJA+1   |    843 |\n",
       "| 202106 | BAJA+2   |   1134 |\n",
       "| 202106 | CONTINUA | 162336 |\n",
       "| 202107 | NA       | 163459 |\n",
       "| 202107 | BAJA+1   |   1137 |\n",
       "| 202108 | NA       | 164822 |\n",
       "\n"
      ],
      "text/plain": [
       "   foto_mes clase_ternaria N     \n",
       "1  201901   BAJA+1            645\n",
       "2  201901   BAJA+2            729\n",
       "3  201901   CONTINUA       122899\n",
       "4  201902   BAJA+1            733\n",
       "5  201902   BAJA+2            707\n",
       "6  201902   CONTINUA       123961\n",
       "7  201903   BAJA+1            708\n",
       "8  201903   BAJA+2            751\n",
       "9  201903   CONTINUA       124508\n",
       "10 201904   BAJA+1            756\n",
       "11 201904   BAJA+2            514\n",
       "12 201904   CONTINUA       125268\n",
       "13 201905   BAJA+1            517\n",
       "14 201905   BAJA+2            692\n",
       "15 201905   CONTINUA       125993\n",
       "16 201906   BAJA+1            696\n",
       "17 201906   BAJA+2            608\n",
       "18 201906   CONTINUA       127430\n",
       "19 201907   BAJA+1            611\n",
       "20 201907   BAJA+2            680\n",
       "21 201907   CONTINUA       128977\n",
       "22 201908   BAJA+1            683\n",
       "23 201908   BAJA+2            577\n",
       "24 201908   CONTINUA       130883\n",
       "25 201909   BAJA+1            581\n",
       "26 201909   BAJA+2            582\n",
       "27 201909   CONTINUA       132594\n",
       "28 201910   BAJA+1            594\n",
       "29 201910   BAJA+2            618\n",
       "30 201910   CONTINUA       134798\n",
       "⋮  ⋮        ⋮              ⋮     \n",
       "64 202010   BAJA+1            544\n",
       "65 202010   BAJA+2            454\n",
       "66 202010   CONTINUA       158171\n",
       "67 202011   BAJA+1            456\n",
       "68 202011   BAJA+2            616\n",
       "69 202011   CONTINUA       159178\n",
       "70 202012   BAJA+1            622\n",
       "71 202012   BAJA+2            619\n",
       "72 202012   CONTINUA       159756\n",
       "73 202101   BAJA+1            622\n",
       "74 202101   BAJA+2            825\n",
       "75 202101   CONTINUA       160080\n",
       "76 202102   BAJA+1            831\n",
       "77 202102   BAJA+2           1032\n",
       "78 202102   CONTINUA       160292\n",
       "79 202103   BAJA+1           1039\n",
       "80 202103   BAJA+2            951\n",
       "81 202103   CONTINUA       161119\n",
       "82 202104   BAJA+1            955\n",
       "83 202104   BAJA+2           1130\n",
       "84 202104   CONTINUA       161333\n",
       "85 202105   BAJA+1           1134\n",
       "86 202105   BAJA+2            842\n",
       "87 202105   CONTINUA       161941\n",
       "88 202106   BAJA+1            843\n",
       "89 202106   BAJA+2           1134\n",
       "90 202106   CONTINUA       162336\n",
       "91 202107   NA             163459\n",
       "92 202107   BAJA+1           1137\n",
       "93 202108   NA             164822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
    "dataset[, .N, list(foto_mes, clase_ternaria)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### Eliminacion de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar a gusto LUEGO de realizar un analisis exploratorio de datos.\n",
    "<br> No necesariamente en esta Segunda Competencia conviele eliminar los mismos campos que en la Primera ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salsa Magica para 202106\n",
    "dataset[, mprestamos_personales := NULL ]\n",
    "dataset[, cprestamos_personales := NULL ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago las sumas de los montos, cantidades, y su division monto/cantidad\n",
    "cols <- names(dataset)[\n",
    "  grepl(\"^(visa_m|master_m|m)\", names(dataset), ignore.case = TRUE) &\n",
    "  !grepl(\"^master\", names(dataset), ignore.case = TRUE)  # excluye master salvo master_m\n",
    "]\n",
    "\n",
    "dataset[, suma_montos := rowSums(.SD, na.rm = TRUE), .SDcols = cols]\n",
    "\n",
    "cols_c <- c(\n",
    "  \"cproductos\",\n",
    "  \"tcuentas\",\n",
    "  \"ccuenta_corriente\",\n",
    "  \"ccaja_ahorro\",\n",
    "  \"ctarjeta_debito\",\n",
    "  \"ctarjeta_debito_transacciones\",\n",
    "  \"ctarjeta_visa\",\n",
    "  \"ctarjeta_visa_transacciones\",\n",
    "  \"ctarjeta_master\",\n",
    "  \"ctarjeta_master_transacciones\",\n",
    "  \"cprestamos_prendarios\",\n",
    "  \"cprestamos_hipotecarios\",\n",
    "  \"cplazo_fijo\",\n",
    "  \"cinversion1\",\n",
    "  \"cinversion2\",\n",
    "  \"cseguro_vida\",\n",
    "  \"cseguro_auto\",\n",
    "  \"cseguro_vivienda\",\n",
    "  \"cseguro_accidentes_personales\",\n",
    "  \"cpayroll_trx\",\n",
    "  \"cpayroll2_trx\",\n",
    "  \"ccuenta_debitos_automaticos\",\n",
    "  \"ctarjeta_visa_debitos_automaticos\",\n",
    "  \"ctarjeta_master_debitos_automaticos\",\n",
    "  \"cpagodeservicios\",\n",
    "  \"cpagomiscuentas\",\n",
    "  \"ccajeros_propios_descuentos\",\n",
    "  \"ctarjeta_visa_descuentos\",\n",
    "  \"ctarjeta_master_descuentos\",\n",
    "  \"ccomisiones_mantenimiento\",\n",
    "  \"ccomisiones_otras\",\n",
    "  \"cforex\",\n",
    "  \"cforex_buy\",\n",
    "  \"cforex_sell\",\n",
    "  \"ctransferencias_recibidas\",\n",
    "  \"ctransferencias_emitidas\",\n",
    "  \"cextraccion_autoservicio\",\n",
    "  \"ccheques_depositados\",\n",
    "  \"ccheques_emitidos\",\n",
    "  \"ccheques_depositados_rechazados\",\n",
    "  \"ccheques_emitidos_rechazados\",\n",
    "  \"ccallcenter_transacciones\",\n",
    "  \"chomebanking_transacciones\",\n",
    "  \"ccajas_transacciones\",\n",
    "  \"ccajas_consultas\",\n",
    "  \"ccajas_depositos\",\n",
    "  \"ccajas_extracciones\",\n",
    "  \"ccajas_otras\",\n",
    "  \"catm_trx\",\n",
    "  \"catm_trx_other\",\n",
    "  \"ctrx_quarter\",\n",
    "  \"cmobile_app_trx\",\n",
    "  \"Master_cconsumos\",\n",
    "  \"Master_cadelantosefectivo\",\n",
    "  \"Visa_cconsumos\",\n",
    "  \"Visa_cadelantosefectivo\"\n",
    ")\n",
    "\n",
    "dataset[, suma_cantidades :=rowSums(.SD, na.rm = TRUE), .SDcols = cols_c]\n",
    "dataset[, ratio_monto_cantidad := fifelse(suma_cantidades > 0, suma_montos / suma_cantidades, NA_real_)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Columnas que son 100% CERO en un mes:\"\n",
      "    foto_mes                           variable\n",
      "       <int>                             <fctr>\n",
      " 1:   201904  ctarjeta_visa_debitos_automaticos\n",
      " 2:   201904 mttarjeta_visa_debitos_automaticos\n",
      " 3:   201905                      mrentabilidad\n",
      " 4:   201905               mrentabilidad_annual\n",
      " 5:   201905                        mcomisiones\n",
      " 6:   201905                    mactivos_margen\n",
      " 7:   201905                    mpasivos_margen\n",
      " 8:   201905                  ccomisiones_otras\n",
      " 9:   201905                  mcomisiones_otras\n",
      "10:   201910                      mrentabilidad\n",
      "11:   201910               mrentabilidad_annual\n",
      "12:   201910                        mcomisiones\n",
      "13:   201910                    mactivos_margen\n",
      "14:   201910                    mpasivos_margen\n",
      "15:   201910        ccajeros_propios_descuentos\n",
      "16:   201910        mcajeros_propios_descuentos\n",
      "17:   201910           ctarjeta_visa_descuentos\n",
      "18:   201910           mtarjeta_visa_descuentos\n",
      "19:   201910         ctarjeta_master_descuentos\n",
      "20:   201910         mtarjeta_master_descuentos\n",
      "21:   201910                  ccomisiones_otras\n",
      "22:   201910                  mcomisiones_otras\n",
      "23:   201910         chomebanking_transacciones\n",
      "24:   202002        ccajeros_propios_descuentos\n",
      "25:   202002        mcajeros_propios_descuentos\n",
      "26:   202002           ctarjeta_visa_descuentos\n",
      "27:   202002           mtarjeta_visa_descuentos\n",
      "28:   202002         ctarjeta_master_descuentos\n",
      "29:   202002         mtarjeta_master_descuentos\n",
      "30:   202006                     active_quarter\n",
      "31:   202006                           internet\n",
      "32:   202006                      mrentabilidad\n",
      "33:   202006               mrentabilidad_annual\n",
      "34:   202006                        mcomisiones\n",
      "35:   202006                    mactivos_margen\n",
      "36:   202006                    mpasivos_margen\n",
      "37:   202006                     mcuentas_saldo\n",
      "38:   202006      ctarjeta_debito_transacciones\n",
      "39:   202006                      mautoservicio\n",
      "40:   202006        ctarjeta_visa_transacciones\n",
      "41:   202006              mtarjeta_visa_consumo\n",
      "42:   202006      ctarjeta_master_transacciones\n",
      "43:   202006            mtarjeta_master_consumo\n",
      "44:   202006        ccajeros_propios_descuentos\n",
      "45:   202006        mcajeros_propios_descuentos\n",
      "46:   202006           ctarjeta_visa_descuentos\n",
      "47:   202006           mtarjeta_visa_descuentos\n",
      "48:   202006         ctarjeta_master_descuentos\n",
      "49:   202006         mtarjeta_master_descuentos\n",
      "50:   202006                  ccomisiones_otras\n",
      "51:   202006                  mcomisiones_otras\n",
      "52:   202006           cextraccion_autoservicio\n",
      "53:   202006           mextraccion_autoservicio\n",
      "54:   202006               ccheques_depositados\n",
      "55:   202006               mcheques_depositados\n",
      "56:   202006                  ccheques_emitidos\n",
      "57:   202006                  mcheques_emitidos\n",
      "58:   202006    ccheques_depositados_rechazados\n",
      "59:   202006    mcheques_depositados_rechazados\n",
      "60:   202006       ccheques_emitidos_rechazados\n",
      "61:   202006       mcheques_emitidos_rechazados\n",
      "62:   202006                        tcallcenter\n",
      "63:   202006          ccallcenter_transacciones\n",
      "64:   202006                       thomebanking\n",
      "65:   202006         chomebanking_transacciones\n",
      "66:   202006               ccajas_transacciones\n",
      "67:   202006                   ccajas_consultas\n",
      "68:   202006                   ccajas_depositos\n",
      "69:   202006                ccajas_extracciones\n",
      "70:   202006                       ccajas_otras\n",
      "71:   202006                           catm_trx\n",
      "72:   202006                               matm\n",
      "73:   202006                     catm_trx_other\n",
      "74:   202006                         matm_other\n",
      "75:   202006                        tmobile_app\n",
      "76:   202006                    cmobile_app_trx\n",
      "77:   202009        ccajeros_propios_descuentos\n",
      "78:   202009        mcajeros_propios_descuentos\n",
      "79:   202009           ctarjeta_visa_descuentos\n",
      "80:   202009           mtarjeta_visa_descuentos\n",
      "81:   202009         ctarjeta_master_descuentos\n",
      "82:   202009         mtarjeta_master_descuentos\n",
      "83:   202010        ccajeros_propios_descuentos\n",
      "84:   202010        mcajeros_propios_descuentos\n",
      "85:   202010           ctarjeta_visa_descuentos\n",
      "86:   202010           mtarjeta_visa_descuentos\n",
      "87:   202010         ctarjeta_master_descuentos\n",
      "88:   202010         mtarjeta_master_descuentos\n",
      "89:   202102        ccajeros_propios_descuentos\n",
      "90:   202102        mcajeros_propios_descuentos\n",
      "91:   202102           ctarjeta_visa_descuentos\n",
      "92:   202102           mtarjeta_visa_descuentos\n",
      "93:   202102         ctarjeta_master_descuentos\n",
      "94:   202102         mtarjeta_master_descuentos\n",
      "95:   202105                   ccajas_depositos\n",
      "    foto_mes                           variable\n"
     ]
    }
   ],
   "source": [
    "# 1. Identificar las columnas numéricas a chequear\n",
    "#    (Excluimos IDs y la propia foto_mes)\n",
    "numeric_types <- c(\"integer\", \"numeric\", \"double\", \"integer64\")\n",
    "all_cols <- names(dataset)\n",
    "\n",
    "# Obtenemos los nombres de las columnas que son numéricas\n",
    "cols_a_chequear <- all_cols[sapply(dataset, function(x) class(x)[1] %in% numeric_types)]\n",
    "\n",
    "# Quitamos las que no son features (ID, fecha)\n",
    "cols_a_chequear <- setdiff(cols_a_chequear, c(\"numero_de_cliente\", \"foto_mes\"))\n",
    "\n",
    "# 2. Calcular el porcentaje de ceros por mes\n",
    "#    (sum(x == 0, na.rm = TRUE) / .N)\n",
    "#    Esto es idéntico a la lógica de Polars: \n",
    "#    - sum(x==0, na.rm=T) equivale a (pl.col(c)==0).sum()\n",
    "#    - .N equivale a pl.len()\n",
    "resumen_wide <- dataset[, \n",
    "                        lapply(.SD, function(x) sum(x == 0, na.rm = TRUE) / .N), \n",
    "                        by = foto_mes, \n",
    "                        .SDcols = cols_a_chequear]\n",
    "\n",
    "# 3. Convertir (melt) la tabla a formato largo\n",
    "resumen_long <- melt(resumen_wide, \n",
    "                     id.vars = \"foto_mes\", \n",
    "                     variable.name = \"variable\", \n",
    "                     value.name = \"porcentaje_ceros\")\n",
    "\n",
    "# 4. Filtrar y crear la lista de problemas\n",
    "#    Nos quedamos solo con los que son 100% ceros (porcentaje == 1)\n",
    "lista_problemas <- resumen_long[porcentaje_ceros == 1, \n",
    "                                .(foto_mes, variable)]\n",
    "\n",
    "setorder(lista_problemas, foto_mes, variable)\n",
    "\n",
    "# 5. Mostrar el resultado\n",
    "print(\"Columnas que son 100% CERO en un mes:\")\n",
    "print(lista_problemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando transformación a NA...\n",
      "¡Transformación completa!\n"
     ]
    }
   ],
   "source": [
    "# Asumimos que 'dataset' y 'lista_problemas' existen\n",
    "\n",
    "cat(\"\\nIniciando transformación a NA...\\n\")\n",
    "\n",
    "# Hacemos una copia para no perder el original (opcional pero recomendado)\n",
    "# dataset_corregido <- copy(dataset)\n",
    "# Si quieres modificar el original, solo usa 'dataset' en el bucle\n",
    "\n",
    "for(i in 1:nrow(lista_problemas)) {\n",
    "  \n",
    "  # Obtenemos el mes y el nombre de la variable\n",
    "  f <- lista_problemas$foto_mes[i]\n",
    "  v <- as.character(lista_problemas$variable[i]) # Nombre de la columna como string\n",
    "  \n",
    "  # Determinamos el tipo de NA (Integer o Double)\n",
    "  na_value <- if (class(dataset[[v]])[1] == \"integer\") {\n",
    "      NA_integer_\n",
    "    } else {\n",
    "      NA_real_\n",
    "    }\n",
    "  \n",
    "  # La magia de data.table:\n",
    "  # 1. Filtramos por el mes [foto_mes == f]\n",
    "  # 2. Usamos (v) := ... para asignar a la columna cuyo nombre está en 'v'\n",
    "  # 3. Asignamos el NA apropiado.\n",
    "  #\n",
    "  # Como 'lista_problemas' garantiza que *todos* los valores\n",
    "  # de esta columna/mes son 0, podemos asignar NA directamente\n",
    "  # sin necesidad de un ifelse.\n",
    "  \n",
    "  dataset[foto_mes == f, (v) := na_value]\n",
    "  \n",
    "}\n",
    "\n",
    "cat(\"¡Transformación completa!\\n\")\n",
    "\n",
    "# Para verificar un caso:\n",
    "# (Reemplaza con un mes y variable de tu 'lista_problemas')\n",
    "# print(dataset[foto_mes == 202010, .(tmobile_app, cmobile_app_trx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:12:28 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 1 × 2\u001b[39m\n",
      "  variable foto_mes_corte\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m internet         \u001b[4m2\u001b[24m\u001b[4m0\u001b[24m\u001b[4m2\u001b[24m010\n",
      "Transformando internet desde 202010 \n",
      "   foto_mes  internet\n",
      "      <int>     <num>\n",
      "1:   202103 0.9476669\n",
      "2:   202104 0.9373141\n",
      "3:   202105 0.9400794\n",
      "4:   202106 0.9505091\n",
      "5:   202107 0.9703942\n",
      "6:   202108 0.9581306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:12:29 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(data.table)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "\n",
    "Sys.time()\n",
    "\n",
    "# --- Parámetros ---\n",
    "vars_a_analizar <- c(\"internet\")\n",
    "umbral <- 0.25\n",
    "\n",
    "# --- 0️⃣ Calcular medias por mes ---\n",
    "mean_long <- dataset %>%\n",
    "  select(foto_mes, all_of(vars_a_analizar)) %>%\n",
    "  pivot_longer(\n",
    "    cols = all_of(vars_a_analizar),\n",
    "    names_to = \"variable\",\n",
    "    values_to = \"valor\"\n",
    "  ) %>%\n",
    "  group_by(foto_mes, variable) %>%\n",
    "  summarise(mean_value = mean(valor, na.rm = TRUE), .groups = \"drop\")\n",
    "\n",
    "# --- 1️⃣ Encontrar mes de corte ---\n",
    "corte_temporal <- mean_long %>%\n",
    "  filter(variable %in% vars_a_analizar) %>%\n",
    "  filter(!is.na(mean_value)) %>%\n",
    "  group_by(variable) %>%\n",
    "  summarise(foto_mes_corte = min(foto_mes[mean_value < umbral], na.rm = TRUE), .groups = \"drop\")\n",
    "\n",
    "print(corte_temporal)\n",
    "\n",
    "# --- 2️⃣ Transformar dataset ---\n",
    "setDT(dataset)\n",
    "setorder(dataset, foto_mes)\n",
    "\n",
    "for (i in seq_len(nrow(corte_temporal))) {\n",
    "  v <- corte_temporal$variable[i]\n",
    "  mes_corte <- corte_temporal$foto_mes_corte[i]\n",
    "  \n",
    "  if (is.finite(mes_corte) && !is.na(mes_corte)) {\n",
    "    cat(\"Transformando\", v, \"desde\", mes_corte, \"\\n\")\n",
    "    dataset[foto_mes >= mes_corte, (v) := 1 - get(v)]\n",
    "  }\n",
    "}\n",
    "\n",
    "# --- 3️⃣ Verificación ---\n",
    "verificacion <- dataset[, lapply(.SD, mean, na.rm = TRUE),\n",
    "                         .SDcols = vars_a_analizar,\n",
    "                         by = foto_mes]\n",
    "\n",
    "print(tail(verificacion))\n",
    "Sys.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Drifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos los índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘data.table’ and 'data.frame':\t32 obs. of  10 variables:\n",
      " $ foto_mes    : int  201901 201902 201903 201904 201905 201906 201907 201908 201909 201910 ...\n",
      " $ TC_BLUE     : num  37.5 39 43.6 46 46 ...\n",
      " $ TC_OFICIAL  : num  38.3 40.1 44.4 45.4 46.1 ...\n",
      " $ TCRM        : num  117 117 120 120 119 ...\n",
      " $ UVA         : num  32 32.9 34 35.4 36.9 ...\n",
      " $ IPC         : num  190 197 206 213 220 ...\n",
      " $ IPIM        : num  279 288 300 314 330 ...\n",
      " $ ripte_indice: num  4042 4199 4445 4533 4676 ...\n",
      " $ tasa_i      : num  0.0371 0.0309 0.0381 0.0445 0.0442 0.0396 0.0414 0.0484 0.0491 0.0406 ...\n",
      " $ tasa_r      : num  0.0079 -0.0068 -0.0085 0.0101 0.0128 0.0123 0.0189 0.0081 -0.0094 0.0073 ...\n",
      " - attr(*, \".internal.selfref\")=<externalptr> \n"
     ]
    }
   ],
   "source": [
    "require(data.table)\n",
    "\n",
    "indices_externos <- data.table(\n",
    "  foto_mes = c(201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908, 201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004, 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106, 202107, 202108),\n",
    "  TC_BLUE = c(\"37,5\", \"39\", \"43,65\", \"46\", \"46\", \"43,8\", \"45,2\", \"63\", \"61,25\", \"69\", \"69,25\", \"78,5\", \"78\", \"78,5\", \"83,5\", \"118\", \"125\", \"126\", \"136\", \"135\", \"146\", \"169\", \"155\", \"166\", \"153\", \"146\", \"141\", \"150\", \"157\", \"168\", \"180,5\", \"182\"),\n",
    "  TC_OFICIAL = c(\"38,28\", \"40,14\", \"44,4\", \"45,36\", \"46,1\", \"43,7\", \"45,02\", \"62,04\", \"59,82\", \"63,23\", \"62,93\", \"62,99\", \"63,03\", \"64,26\", \"66,58\", \"69,16\", \"70,76\", \"74,07\", \"76,39\", \"78,36\", \"80,63\", \"83,89\", \"86,72\", \"89,87\", \"92,7\", \"95,12\", \"97,69\", \"98,9\", \"100,09\", \"101,17\", \"102,06\", \"103,14\"),\n",
    "  TCRM = c(\"116,5734916\", \"116,5625812\", \"119,8157416\", \"120,2150629\", \"119,4975567\", \"114,8101224\", \"109,8715912\", \"127,7565287\", \"130,6961531\", \"129,7797576\", \"126,9467229\", \"123,5951113\", \"120,8372653\", \"118,9226283\", \"114,5040182\", \"111,5867304\", \"111,7626924\", \"116,6307121\", \"117,9781145\", \"118,9579865\", \"119,6485855\", \"118,1736932\", \"119,6199112\", \"123,235859\", \"122,8366223\", \"122,3839332\", \"119,0439564\", \"116,7635839\", \"117,2617246\", \"116,9865438\", \"113,7702507\", \"111,9430182\"),\n",
    "  UVA = c(\"32,03\", \"32,86\", \"33,97\", \"35,42\", \"36,89\", \"38,03\", \"39,2\", \"40,16\", \"41,26\", \"43,43\", \"45,42\", \"47,16\", \"49,05\", \"50,49\", \"51,62\", \"52,95\", \"54,24\", \"55,06\", \"56,09\", \"57,17\", \"58,52\", \"60,16\", \"61,94\", \"64,32\", \"66,54\", \"69,04\", \"71,92\", \"74,87\", \"78,07\", \"81,13\", \"83,82\", \"86,42\"),\n",
    "  IPC = c(\"189,6101\", \"196,7501\", \"205,9571\", \"213,0517\", \"219,5691\", \"225,537\", \"230,494\", \"239,6077\", \"253,7102\", \"262,0661\", \"273,2158\", \"283,4442\", \"289,8299\", \"295,666\", \"305,5515\", \"310,1243\", \"314,9087\", \"321,9738\", \"328,2014\", \"337,0632\", \"346,6207\", \"359,657\", \"371,0211\", \"385,8826\", \"401,5071\", \"415,8595\", \"435,8657\", \"453,6503\", \"468,725\", \"483,6049\", \"498,0987\", \"510,3942\"),\n",
    "  IPIM = c(\"279\", \"288,4\", \"300,2\", \"314\", \"329,5\", \"334,9\", \"335,2\", \"372,8\", \"388,3\", \"402,3\", \"424\", \"439,7\", \"446,3\", \"451,3\", \"455,6\", \"449,7\", \"451,3\", \"467,8\", \"484,4\", \"504,2\", \"522,9\", \"547,3\", \"570,1\", \"595,2\", \"628,3\", \"666,5\", \"692,4\", \"725,5\", \"748,8\", \"772,3\", \"789,5\", \"809,4\"),\n",
    "  ripte_indice = c(\"4042\", \"4198,76\", \"4444,6\", \"4533,03\", \"4676,25\", \"4753,19\", \"4948,27\", \"5039,93\", \"5199,08\", \"5467,59\", \"5554,15\", \"5666,48\", \"6066,07\", \"6445,13\", \"6500,72\", \"6510,18\", \"6521,87\", \"6670,93\", \"6908,52\", \"6945,86\", \"7076,47\", \"7401,81\", \"7495,03\", \"7643,41\", \"7784,1\", \"8263,33\", \"8665,19\", \"9201,59\", \"9311,61\", \"9660,13\", \"10089,96\", \"10326,11\"),\n",
    "  tasa_i = c(\"3,71\", \"3,09\", \"3,81\", \"4,45\", \"4,42\", \"3,96\", \"4,14\", \"4,84\", \"4,91\", \"4,06\", \"3,68\", \"3,29\", \"2,83\", \"2,65\", \"2,30\", \"1,54\", \"2,21\", \"2,47\", \"2,43\", \"2,47\", \"2,47\", \"2,65\", \"2,81\", \"2,85\", \"2,85\", \"2,80\", \"2,84\", \"2,84\", \"2,84\", \"2,84\", \"2,84\", \"2,85\"),\n",
    "  tasa_r = c(\"0,79\", \"-0,68\", \"-0,85\", \"1,01\", \"1,28\", \"1,23\", \"1,89\", \"0,81\", \"-0,94\", \"0,73\", \"-0,59\", \"-0,40\", \"0,52\", \"0,64\", \"-0,97\", \"0,04\", \"0,70\", \"0,27\", \"0,52\", \"-0,23\", \"-0,32\", \"-1,11\", \"-0,38\", \"-1,10\", \"-1,11\", \"-0,77\", \"-1,87\", \"-1,21\", \"-0,44\", \"-0,35\", \"-0,15\", \"0,34\")\n",
    ")\n",
    "\n",
    "# Trabajamos el formato\n",
    "indices_externos[, foto_mes := as.integer(foto_mes)]\n",
    "\n",
    "# Reemplazar la coma por el punto en todas las columnas excepto 'foto_mes'\n",
    "columnas_numericas <- names(indices_externos)[-1]\n",
    "\n",
    "indices_externos[, (columnas_numericas) := lapply(.SD, function(x) as.numeric(gsub(\",\", \".\", x))), \n",
    "                 .SDcols = columnas_numericas]\n",
    "\n",
    "# convertir a tasa\n",
    "cols_tasas <- c(\"tasa_i\", \"tasa_r\")\n",
    "indices_externos[, (cols_tasas) := lapply(.SD, function(x) x / 100), .SDcols = cols_tasas]\n",
    "\n",
    "# Verificar la estructura de la tabla\n",
    "str(indices_externos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "\n",
    "#' @title Deflacta columnas monetarias SOBREESCRIBIENDO las originales\n",
    "#' @description Modifica las columnas monetarias (ej: 'mrentabilidad')\n",
    "#'              directamente con su valor deflactado.\n",
    "#'\n",
    "#' @param dt El data.table principal (ej: 'dataset') que se modificará.\n",
    "#' @param dt_indices El data.table que contiene todos los índices (ej: 'indices_externos').\n",
    "#' @param criterio_deflacion El nombre de la columna a usar (ej: \"IPC\", \"TCRM\", \"tasa_i\").\n",
    "#' @param incluir_dolarizadas TRUE o FALSE. Si es TRUE, ajusta pesos Y dólares.\n",
    "#'                            Si es FALSE, ajusta SÓLO pesos.\n",
    "#' @param mes_base Un integer (YYYYMM). Mes base para normalizar (ej: 201901).\n",
    "#'\n",
    "#' @return El data.table 'dt' modificado por referencia (no es necesario reasignarlo).\n",
    "\n",
    "deflactar_dataset <- function(dt, \n",
    "                                       dt_indices, \n",
    "                                       criterio_deflacion, \n",
    "                                       incluir_dolarizadas = FALSE, \n",
    "                                       mes_base = 201901) {\n",
    "\n",
    "  cat(paste0(\"Iniciando deflación según Criterio: \", criterio_deflacion, \"\\n\"))\n",
    "\n",
    "  # --- 1. Definir Lógicas y Columnas ---\n",
    "  \n",
    "  # Grupo 1: Variables en PESOS\n",
    "  columnas_pesos <- c(\n",
    "    \"mrentabilidad\", \"mrentabilidad_annual\", \"mcomisiones\", \"mactivos_margen\",\n",
    "    \"mpasivos_margen\", \"mcuentas_saldo\", \"mcuenta_corriente\", \"mcaja_ahorro\",\n",
    "    \"mcuenta_corriente_adicional\", \"mcaja_ahorro_adicional\",\n",
    "    \"mprestamos_personales\", \"mprestamos_prendarios\", \"mprestamos_hipotecarios\",\n",
    "    \"mplazo_fijo_pesos\", \"minversion1_pesos\", \"minversion2\",\n",
    "    \"mpayroll\", \"mpayroll2\", \"mcuenta_debitos_automaticos\",\n",
    "    \"mtarjeta_visa_consumo\", \"mtarjeta_master_consumo\",\n",
    "    \"mttarjeta_visa_debitos_automaticos\", \"mttarjeta_master_debitos_automaticos\",\n",
    "    \"mpagodeservicios\", \"mpagomiscuentas\", \"mtransferencias_recibidas\",\n",
    "    \"mtransferencias_emitidas\", \"mextraccion_autoservicio\", \"mcheques_depositados\",\n",
    "    \"mcheques_emitidos\", \"mcheques_depositados_rechazados\", \"mcheques_emitidos_rechazados\",\n",
    "    \"matm\", \"matm_other\", \"mautoservicio\",\n",
    "    \"mcomisiones_mantenimiento\", \"mcomisiones_otras\", \"mforex_buy\", \"mforex_sell\",\n",
    "    \"mcajeros_propios_descuentos\", \"mtarjeta_visa_descuentos\", \"mtarjeta_master_descuentos\",\n",
    "    \"Master_mfinanciacion_limite\", \"Master_msaldototal\", \"Master_msaldopesos\",\n",
    "    \"Master_mconsumospesos\", \"Master_mlimitecompra\", \"Master_madelantopesos\",\n",
    "    \"Master_mpagado\", \"Master_mpagospesos\", \"Master_mconsumototal\", \"Master_mpagominimo\",\n",
    "    \"Visa_mfinanciacion_limite\", \"Visa_msaldototal\", \"Visa_msaldopesos\",\n",
    "    \"Visa_mconsumospesos\", \"Visa_mlimitecompra\", \"Visa_madelantopesos\",\n",
    "    \"Visa_mpagado\", \"Visa_mpagospesos\", \"Visa_mconsumototal\", \"Visa_mpagominimo\"\n",
    "  )\n",
    "  \n",
    "  # Grupo 2: Variables DOLARIZADAS\n",
    "  columnas_dolares <- c(\n",
    "    \"mcaja_ahorro_dolares\", \"mplazo_fijo_dolares\", \"minversion1_dolares\",\n",
    "    \"Master_msaldodolares\", \"Master_mconsumosdolares\", \"Master_madelantodolares\",\n",
    "    \"Master_mpagosdolares\",\n",
    "    \"Visa_msaldodolares\", \"Visa_mconsumosdolares\", \"Visa_madelantodolares\",\n",
    "    \"Visa_mpagosdolares\"\n",
    "  )\n",
    "\n",
    "  # Grupos de lógicas (actualizados a tu tabla final)\n",
    "  grupo_indices <- c(\"IPC\", \"IPIM\", \"UVA\", \"ripte_indice\") # Se fueron CER e indice_salarios\n",
    "  grupo_tc <- c(\"TC_BLUE\", \"TC_OFICIAL\", \"TCRM\") # Se fue TC_MAYORISTA, TC_MINORISTA\n",
    "  grupo_tasas <- c(\"tasa_i\", \"tasa_r\") # Nombres actualizados\n",
    "\n",
    "  # --- 2. Validar Entradas ---\n",
    "  if (!criterio_deflacion %in% names(dt_indices)) {\n",
    "     stop(paste(\"La columna de criterio '\", criterio_deflacion, \"' NO existe en 'indices_externos'.\"))\n",
    "  }\n",
    "  \n",
    "  # --- 3. Preparar el Índice Normalizado ---\n",
    "  dt_indice_temporal <- dt_indices[, .(foto_mes, INDICE_TEMP = get(criterio_deflacion))]\n",
    "  setorder(dt_indice_temporal, foto_mes)\n",
    "  valor_base <- dt_indice_temporal[foto_mes == mes_base, INDICE_TEMP]\n",
    "  if (length(valor_base) == 0 | is.na(valor_base)) {\n",
    "    stop(paste(\"El 'mes_base'\", mes_base, \"no se encontró o es NA en el índice.\"))\n",
    "  }\n",
    "\n",
    "  if (criterio_deflacion %in% grupo_indices) {\n",
    "    cat(\"... Aplicando Lógica de ÍNDICE (Base 1.0)\\n\")\n",
    "    dt_indice_temporal[, indice_normalizado := INDICE_TEMP / valor_base]\n",
    "  } else if (criterio_deflacion %in% grupo_tasas) {\n",
    "    cat(\"... Aplicando Lógica de TASA DE INTERÉS\\n\")\n",
    "    dt_indice_temporal[, factor := 1 + INDICE_TEMP]\n",
    "    dt_indice_temporal[, indice_compuesto := cumprod(factor)]\n",
    "    valor_base_compuesto <- dt_indice_temporal[foto_mes == mes_base, indice_compuesto]\n",
    "    dt_indice_temporal[, indice_normalizado := indice_compuesto / valor_base_compuesto]\n",
    "  } else if (criterio_deflacion %in% grupo_tc) {\n",
    "    cat(\"... Aplicando Lógica de TIPO DE CAMBIO\\n\")\n",
    "    dt_indice_temporal[, indice_normalizado := INDICE_TEMP]\n",
    "  } else {\n",
    "    warning(paste(\"Criterio '\", criterio_deflacion, \"' no está en un grupo predefinido. Se usará la Lógica de ÍNDICE por defecto.\"))\n",
    "    dt_indice_temporal[, indice_normalizado := INDICE_TEMP / valor_base]\n",
    "  }\n",
    "  \n",
    "  dt_indice_para_merge <- dt_indice_temporal[, .(foto_mes, indice_normalizado)]\n",
    "\n",
    "  # --- 4. Unir el índice al dataset principal (Modifica 'dt' por referencia) ---\n",
    "  dt[dt_indice_para_merge, on = \"foto_mes\", indice_normalizado := i.indice_normalizado]\n",
    "\n",
    "  # --- 5. Seleccionar columnas a deflactar ---\n",
    "  cols_a_deflactar_final <- columnas_pesos\n",
    "  if (incluir_dolarizadas) {\n",
    "    cols_a_deflactar_final <- c(cols_a_deflactar_final, columnas_dolares)\n",
    "  }\n",
    "  cols_a_deflactar_final <- intersect(cols_a_deflactar_final, names(dt))\n",
    "  \n",
    "  if (length(cols_a_deflactar_final) == 0) {\n",
    "    cat(\"Advertencia: Ninguna columna a deflactar fue encontrada. No se hizo nada.\\n\")\n",
    "    dt[, indice_normalizado := NULL] # Limpiar la columna de índice\n",
    "    return(dt)\n",
    "  }\n",
    "\n",
    "  # --- 6. Aplicar la deflación (SOBRESCRITURA) ---\n",
    "  #     (ej: mrentabilidad = mrentabilidad / indice_normalizado)\n",
    "  dt[, (cols_a_deflactar_final) := lapply(.SD, function(x) {\n",
    "              x / indice_normalizado\n",
    "            }), .SDcols = cols_a_deflactar_final]\n",
    "\n",
    "  # --- 7. Limpiar columna de índice ---\n",
    "  dt[, indice_normalizado := NULL]\n",
    "\n",
    "  cat(\"Deflación completada.\", length(cols_a_deflactar_final), \"columnas fueron SOBREESCRITAS.\\n\")\n",
    "  \n",
    "  # Limpieza de memoria\n",
    "  rm(dt_indice_temporal, dt_indice_para_merge, cols_a_deflactar_final, \n",
    "     columnas_pesos, columnas_dolares, grupo_indices, grupo_tc, grupo_tasas)\n",
    "  gc()\n",
    "  \n",
    "  return(dt) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicamos una metodología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando deflación según Criterio: UVA\n",
      "... Aplicando Lógica de ÍNDICE (Base 1.0)\n",
      "Deflación completada. 61 columnas fueron SOBREESCRITAS.\n"
     ]
    }
   ],
   "source": [
    "# (En la celda de Data Drifting)\n",
    "deflactar_dataset(\n",
    "  dt = dataset, \n",
    "  dt_indices = indices_externos, \n",
    "  criterio_deflacion = \"UVA\", #IPC , IPIM, UVA, ripte_indice, TC_BLUE, TC_OFICIAL, TCRM, tasa_i, tasa_r\n",
    "  incluir_dolarizadas = FALSE,  # si es true afecta las columnas en dólares\n",
    "  mes_base = 201901  #mes al que lleva el valor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# require(data.table)\n",
    "\n",
    "# #' @title Rankea columnas monetarias por mes (SOBREESCRIBIENDO)\n",
    "# #' @description Normaliza las columnas monetarias en un rango de [-1, 1]\n",
    "# #'              agrupando por foto_mes y tratando positivos y negativos\n",
    "# #'              por separado.\n",
    "# #'\n",
    "# #' @param p_dataset El data.table a modificar.\n",
    "\n",
    "# rank_normalizar_por_mes_monetarias <- function(p_dataset) {\n",
    "  \n",
    "#   # 1. Define el vector con los nombres BASE de las columnas monetarias\n",
    "#   columnas_monetarias_base <- c(\n",
    "#     \"mrentabilidad\", \"mrentabilidad_annual\", \"mcomisiones\", \"mactivos_margen\",\n",
    "#     \"mpasivos_margen\", \"mcuenta_corriente_adicional\", \"mcuenta_corriente\",\n",
    "#     \"mcaja_ahorro\", \"mcaja_ahorro_adicional\", \"mcaja_ahorro_dolares\",\n",
    "#     \"mcuentas_saldo\", \"mautoservicio\", \"mtarjeta_visa_consumo\",\n",
    "#     \"mtarjeta_master_consumo\", \"mprestamos_personales\", \"mprestamos_prendarios\",\n",
    "#     \"mprestamos_hipotecarios\", \"mplazo_fijo_dolares\", \"mplazo_fijo_pesos\",\n",
    "#     \"minversion1_pesos\", \"minversion1_dolares\", \"minversion2\", \"mpayroll\",\n",
    "#     \"mpayroll2\", \"mcuenta_debitos_automaticos\", \"mtarjeta_visa_debitos_automaticos\",\n",
    "#     \"mttarjeta_master_debitos_automaticos\", \"mpagodeservicios\", \"mpagomiscuentas\",\n",
    "#     \"mcajeros_propios_descuentos\", \"mtarjeta_visa_descuentos\",\n",
    "#     \"mtarjeta_master_descuentos\", \"mcomisiones_mantenimiento\", \"mcomisiones_otras\",\n",
    "#     \"mforex_buy\", \"mforex_sell\", \"mtransferencias_recibidas\", \"mtransferencias_emitidas\",\n",
    "#     \"mextraccion_autoservicio\", \"mcheques_depositados\", \"mcheques_emitidos\",\n",
    "#     \"mcheques_depositados_rechazados\", \"mcheques_emitidos_rechazados\", \"matm\",\n",
    "#     \"matm_other\", \"Master_mfinanciacion_limite\", \"Master_msaldototal\",\n",
    "#     \"Master_msaldopesos\", \"Master_msaldodolares\", \"Master_mconsumospesos\",\n",
    "#     \"Master_mconsumosdolares\", \"Master_mlimitecompra\", \"Master_madelantopesos\",\n",
    "#     \"Master_madelantodolares\", \"Master_mpagado\", \"Master_mpagospesos\",\n",
    "#     \"Master_mpagosdolares\", \"Master_mconsumototal\", \"Master_mpagominimo\",\n",
    "#     \"Visa_mfinanciacion_limite\", \"Visa_msaldototal\", \"Visa_msaldopesos\",\n",
    "#     \"Visa_msaldodolares\", \"Visa_mconsumospesos\", \"Visa_mconsumosdolares\",\n",
    "#     \"Visa_mlimitecompra\", \"Visa_madelantopesos\", \"Visa_madelantodolares\",\n",
    "#     \"Visa_mpagado\", \"Visa_mpagospesos\", \"Visa_mpagosdolares\", \"Visa_mconsumototal\",\n",
    "#     \"Visa_mpagominimo\"\n",
    "#   )\n",
    "  \n",
    "#   # 2. Selecciona solo las columnas que realmente existen en el dataset\n",
    "#   columnas_a_rankear <- intersect(columnas_monetarias_base, names(p_dataset))\n",
    "\n",
    "\n",
    "#   cat(\"Columnas a rankear por mes (sobrescribiendo):\", length(columnas_a_rankear), \"\\n\")\n",
    "#   if (length(columnas_a_rankear) == 0) {\n",
    "#     cat(\"Advertencia: Ninguna de las columnas monetarias especificadas se encontró en el dataset.\\n\")\n",
    "#     return(invisible(p_dataset))\n",
    "#   }\n",
    "\n",
    "#   for (col in columnas_a_rankear) {\n",
    "    \n",
    "#     p_dataset[, (col) := {\n",
    "#       v <- .SD[[1]]\n",
    "#       r <- numeric(length(v))\n",
    "\n",
    "#       pos_idx <- which(v > 0)\n",
    "#       neg_idx <- which(v < 0)\n",
    "\n",
    "#       if (length(pos_idx) > 0) {\n",
    "#         r[pos_idx] <- frank(v[pos_idx], ties.method = \"average\") / length(pos_idx)\n",
    "#       }\n",
    "#       if (length(neg_idx) > 0) {\n",
    "#         r[neg_idx] <- -frank(-v[neg_idx], ties.method = \"average\") / length(neg_idx)\n",
    "#       }\n",
    "\n",
    "#       r[v == 0] <- 0\n",
    "\n",
    "#       # Segunda normalización para asegurar el rango [-1, 1]\n",
    "#       max_r_pos <- max(r[pos_idx], 0, na.rm = TRUE)\n",
    "#       min_r_neg <- min(r[neg_idx], 0, na.rm = TRUE)\n",
    "\n",
    "#       if (max_r_pos > 0) r[pos_idx] <- r[pos_idx] / max_r_pos\n",
    "#       if (min_r_neg < 0) r[neg_idx] <- r[neg_idx] / abs(min_r_neg)\n",
    "\n",
    "#       .(r)\n",
    "#     }, by = foto_mes, .SDcols = col]\n",
    "#   }\n",
    "\n",
    "\n",
    "\n",
    "#   cat(\"Rankeo completado. Las columnas fueron sobrescritas.\\n\")\n",
    "#   gc()\n",
    "#   invisible(p_dataset)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aplico la función\n",
    "# rank_normalizar_por_mes_monetarias(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Intra-Mes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear variables nuevas a partir de las existentes dentro del mismo registro, **sin** ir a buscar información histórica.\n",
    "<br> El siguiente código es un mínimo ejemplo, agregar nuevos features a gusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:12:31 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# el mes 1,2, ..12 , podria servir para detectar estacionalidad\n",
    "dataset[, kmes := foto_mes %% 100]\n",
    "\n",
    "# creo un ctr_quarter que tenga en cuenta cuando\n",
    "# los clientes hace 3 menos meses que estan\n",
    "# ya que seria injusto considerar las transacciones medidas en menor tiempo\n",
    "dataset[, ctrx_quarter_normalizado := as.numeric(ctrx_quarter) ]\n",
    "dataset[cliente_antiguedad == 1, ctrx_quarter_normalizado := ctrx_quarter * 5.0]\n",
    "dataset[cliente_antiguedad == 2, ctrx_quarter_normalizado := ctrx_quarter * 2.0]\n",
    "dataset[cliente_antiguedad == 3, ctrx_quarter_normalizado := ctrx_quarter * 1.2]\n",
    "\n",
    "# variable extraida de una tesis de maestria de Irlanda, se perdió el link\n",
    "dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering a partir de hojas de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lightgbm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En esta función lo que hago no es poner las 320 dummies de arbol y hoja, sino directamente sumar las veces que cae en cada hoja. Tendria 16 variables.\n",
    "AgregaVarRandomForest <- function() {\n",
    "\n",
    "  cat(\"Inicio AgregaVarRandomForest()\\n\")\n",
    "  gc(verbose = FALSE)\n",
    "\n",
    "  # genero clase binaria\n",
    "  dataset[, clase01 := 0L ]\n",
    "  dataset[ clase_ternaria %in% c(\"BAJA+2\", \"BAJA+1\"), clase01 := 1L ]\n",
    "\n",
    "  # variables modelo\n",
    "  campos_buenos <- setdiff(\n",
    "    colnames(dataset),\n",
    "    c(\"clase_ternaria\", \"clase01\")\n",
    "  )\n",
    "\n",
    "  # defino entrenamiento\n",
    "  dataset[, entrenamiento :=\n",
    "            as.integer(foto_mes %in% PARAM$FE_rf$train$training)]\n",
    "\n",
    "  # arma dtrain\n",
    "  dtrain <- lgb.Dataset(\n",
    "    data  = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
    "    label = dataset[entrenamiento == TRUE, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "\n",
    "  # ENTRENAMIENTO\n",
    "  modelo <- lgb.train(\n",
    "    data   = dtrain,\n",
    "    param  = PARAM$FE_rf$lgb_param,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"Fin construcción RandomForest\\n\")\n",
    "\n",
    "  # guardo modelo\n",
    "  lgb.save(modelo, file = \"modelo.model\")\n",
    "\n",
    "  # periodos únicos\n",
    "  periodos <- dataset[, unique(foto_mes)]\n",
    "\n",
    "  # ---- LOOP POR PERIODO ----\n",
    "  for(periodo in periodos) {\n",
    "\n",
    "    cat(\"\\n>>> Procesando periodo =\", periodo, \"\\n\")\n",
    "\n",
    "    # matriz del periodo\n",
    "    datamatrix <- data.matrix(dataset[foto_mes == periodo, campos_buenos, with = FALSE])\n",
    "\n",
    "    cat(\"  Generando predicciones tipo 'leaf'...\\n\")\n",
    "    prediccion <- predict(\n",
    "      modelo,\n",
    "      datamatrix,\n",
    "      type = \"leaf\"   # hoja por cada árbol\n",
    "    )\n",
    "    cat(\"  OK\\n\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    #  FEATURES AGREGADOS POR HOJA (LA PARTE IMPORTANTE)\n",
    "    # ------------------------------------------------------------\n",
    "    cat(\"  Creando features agregados por hoja...\\n\")\n",
    "\n",
    "    # todas las hojas posibles del bosque en este periodo\n",
    "    todas_hojas <- sort(unique(as.vector(prediccion)))\n",
    "\n",
    "    # por cada hoja: cuántos árboles devolvieron esa hoja\n",
    "    for(h in todas_hojas) {\n",
    "\n",
    "      dataset[ foto_mes == periodo,\n",
    "               paste0(\"rf_hoja_\", sprintf(\"%03d\", h)) :=\n",
    "                 rowSums(prediccion == h) ]\n",
    "    }\n",
    "\n",
    "    rm(prediccion)\n",
    "    rm(datamatrix)\n",
    "    gc(verbose = FALSE)\n",
    "  }\n",
    "\n",
    "  # limpio variable auxiliar\n",
    "  dataset[, clase01 := NULL ]\n",
    "\n",
    "  gc(verbose = FALSE)\n",
    "  cat(\"Fin AgregaVarRandomForest()\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros de Feature Engineering  a partir de hojas de Random Forest\n",
    "\n",
    "# Estos CUATRO parametros son los que se deben modificar\n",
    "PARAM$FE_rf$arbolitos= 20\n",
    "PARAM$FE_rf$hojas_por_arbol= 16\n",
    "PARAM$FE_rf$datos_por_hoja= 100\n",
    "PARAM$FE_rf$mtry_ratio= 0.2\n",
    "\n",
    "\n",
    "# Estos son quasi fijos\n",
    "PARAM$FE_rf$train$training <- c( 202101, 202102, 202103)\n",
    "\n",
    "# Estos TAMBIEN son quasi fijos\n",
    "PARAM$FE_rf$lgb_param <-list(\n",
    "    # parametros que se pueden cambiar\n",
    "    num_iterations = PARAM$FE_rf$arbolitos,\n",
    "    num_leaves  = PARAM$FE_rf$hojas_por_arbol,\n",
    "    min_data_in_leaf = PARAM$FE_rf$datos_por_hoja,\n",
    "    feature_fraction_bynode  = PARAM$FE_rf$mtry_ratio,\n",
    "\n",
    "    # para que LightGBM emule Random Forest\n",
    "    boosting = \"rf\",\n",
    "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
    "    bagging_freq = 1.0,\n",
    "    feature_fraction = 1.0,\n",
    "\n",
    "    # genericos de LightGBM\n",
    "    max_bin = 31L,\n",
    "    objective = \"binary\",\n",
    "    first_metric_only = TRUE,\n",
    "    boost_from_average = TRUE,\n",
    "    feature_pre_filter = FALSE,\n",
    "    force_row_wise = TRUE,\n",
    "    verbosity = -100,\n",
    "    max_depth = -1L,\n",
    "    min_gain_to_split = 0.0,\n",
    "    min_sum_hessian_in_leaf = 0.001,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "\n",
    "    pos_bagging_fraction = 1.0,\n",
    "    neg_bagging_fraction = 1.0,\n",
    "    is_unbalance = FALSE,\n",
    "    scale_pos_weight = 1.0,\n",
    "\n",
    "    drop_rate = 0.1,\n",
    "    max_drop = 50,\n",
    "    skip_drop = 0.5,\n",
    "\n",
    "    extra_trees = FALSE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio AgregaVarRandomForest()\n",
      "Fin construcción RandomForest\n",
      "\n",
      ">>> Procesando periodo = 201901 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201902 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201903 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201904 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201905 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201906 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201907 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201908 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201909 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201910 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201911 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 201912 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202001 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202002 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202003 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202004 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202005 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202006 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202007 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202008 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202009 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202010 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202011 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202012 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202101 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202102 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202103 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202104 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202105 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202106 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202107 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "\n",
      ">>> Procesando periodo = 202108 \n",
      "  Generando predicciones tipo 'leaf'...\n",
      "  OK\n",
      "  Creando features agregados por hoja...\n",
      "Fin AgregaVarRandomForest()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:13:04 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering agregando variables de Random Forest\n",
    "#  aqui es donde se hace el trabajo\n",
    "AgregaVarRandomForest()\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 12 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>foto_mes</th><th scope=col>clase_ternaria</th><th scope=col>rf_hoja_015</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>202008</td><td>CONTINUA</td><td>0</td></tr>\n",
       "\t<tr><td>202009</td><td>CONTINUA</td><td>1</td></tr>\n",
       "\t<tr><td>202010</td><td>CONTINUA</td><td>1</td></tr>\n",
       "\t<tr><td>202011</td><td>CONTINUA</td><td>0</td></tr>\n",
       "\t<tr><td>202012</td><td>CONTINUA</td><td>1</td></tr>\n",
       "\t<tr><td>202101</td><td>CONTINUA</td><td>3</td></tr>\n",
       "\t<tr><td>202102</td><td>CONTINUA</td><td>3</td></tr>\n",
       "\t<tr><td>202103</td><td>CONTINUA</td><td>1</td></tr>\n",
       "\t<tr><td>202104</td><td>CONTINUA</td><td>1</td></tr>\n",
       "\t<tr><td>202105</td><td>CONTINUA</td><td>1</td></tr>\n",
       "\t<tr><td>202106</td><td>BAJA+2  </td><td>2</td></tr>\n",
       "\t<tr><td>202107</td><td>BAJA+1  </td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 12 × 3\n",
       "\\begin{tabular}{lll}\n",
       " foto\\_mes & clase\\_ternaria & rf\\_hoja\\_015\\\\\n",
       " <int> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 202008 & CONTINUA & 0\\\\\n",
       "\t 202009 & CONTINUA & 1\\\\\n",
       "\t 202010 & CONTINUA & 1\\\\\n",
       "\t 202011 & CONTINUA & 0\\\\\n",
       "\t 202012 & CONTINUA & 1\\\\\n",
       "\t 202101 & CONTINUA & 3\\\\\n",
       "\t 202102 & CONTINUA & 3\\\\\n",
       "\t 202103 & CONTINUA & 1\\\\\n",
       "\t 202104 & CONTINUA & 1\\\\\n",
       "\t 202105 & CONTINUA & 1\\\\\n",
       "\t 202106 & BAJA+2   & 2\\\\\n",
       "\t 202107 & BAJA+1   & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 12 × 3\n",
       "\n",
       "| foto_mes &lt;int&gt; | clase_ternaria &lt;chr&gt; | rf_hoja_015 &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 202008 | CONTINUA | 0 |\n",
       "| 202009 | CONTINUA | 1 |\n",
       "| 202010 | CONTINUA | 1 |\n",
       "| 202011 | CONTINUA | 0 |\n",
       "| 202012 | CONTINUA | 1 |\n",
       "| 202101 | CONTINUA | 3 |\n",
       "| 202102 | CONTINUA | 3 |\n",
       "| 202103 | CONTINUA | 1 |\n",
       "| 202104 | CONTINUA | 1 |\n",
       "| 202105 | CONTINUA | 1 |\n",
       "| 202106 | BAJA+2   | 2 |\n",
       "| 202107 | BAJA+1   | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "   foto_mes clase_ternaria rf_hoja_015\n",
       "1  202008   CONTINUA       0          \n",
       "2  202009   CONTINUA       1          \n",
       "3  202010   CONTINUA       1          \n",
       "4  202011   CONTINUA       0          \n",
       "5  202012   CONTINUA       1          \n",
       "6  202101   CONTINUA       3          \n",
       "7  202102   CONTINUA       3          \n",
       "8  202103   CONTINUA       1          \n",
       "9  202104   CONTINUA       1          \n",
       "10 202105   CONTINUA       1          \n",
       "11 202106   BAJA+2         2          \n",
       "12 202107   BAJA+1         1          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[numero_de_cliente==1548033591, .(foto_mes,clase_ternaria, rf_hoja_015)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if( !require(\"Rcpp\")) install.packages(\"Rcpp\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"Rcpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se calculan para los 6 meses previos el minimo, maximo y\n",
    "#  tendencia calculada con cuadrados minimos\n",
    "# la formula de calculo de la tendencia puede verse en\n",
    "#  https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
    "# para la maxíma velocidad esta funcion esta escrita en lenguaje C,\n",
    "# y no en la porqueria de R o Python\n",
    "\n",
    "cppFunction(\"NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde )\n",
    "{\n",
    "  /* Aqui se cargan los valores para la regresion */\n",
    "  double  x[100] ;\n",
    "  double  y[100] ;\n",
    "\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out( 5*n );\n",
    "\n",
    "  for(int i = 0; i < n; i++)\n",
    "  {\n",
    "    //lag\n",
    "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
    "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
    "\n",
    "\n",
    "    int  libre    = 0 ;\n",
    "    int  xvalor   = 1 ;\n",
    "\n",
    "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
    "    {\n",
    "       double a = pcolumna[j] ;\n",
    "\n",
    "       if( !R_IsNA( a ) )\n",
    "       {\n",
    "          y[ libre ]= a ;\n",
    "          x[ libre ]= xvalor ;\n",
    "          libre++ ;\n",
    "       }\n",
    "\n",
    "       xvalor++ ;\n",
    "    }\n",
    "\n",
    "    /* Si hay al menos dos valores */\n",
    "    if( libre > 1 )\n",
    "    {\n",
    "      double  xsum  = x[0] ;\n",
    "      double  ysum  = y[0] ;\n",
    "      double  xysum = xsum * ysum ;\n",
    "      double  xxsum = xsum * xsum ;\n",
    "      double  vmin  = y[0] ;\n",
    "      double  vmax  = y[0] ;\n",
    "\n",
    "      for( int h=1; h<libre; h++)\n",
    "      {\n",
    "        xsum  += x[h] ;\n",
    "        ysum  += y[h] ;\n",
    "        xysum += x[h]*y[h] ;\n",
    "        xxsum += x[h]*x[h] ;\n",
    "\n",
    "        if( y[h] < vmin )  vmin = y[h] ;\n",
    "        if( y[h] > vmax )  vmax = y[h] ;\n",
    "      }\n",
    "\n",
    "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
    "      out[ i + n ]    =  vmin ;\n",
    "      out[ i + 2*n ]  =  vmax ;\n",
    "      out[ i + 3*n ]  =  ysum / libre ;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      out[ i       ]  =  NA_REAL ;\n",
    "      out[ i + n   ]  =  NA_REAL ;\n",
    "      out[ i + 2*n ]  =  NA_REAL ;\n",
    "      out[ i + 3*n ]  =  NA_REAL ;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return  out;\n",
    "}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula la tendencia de las variables cols de los ultimos 6 meses\n",
    "# la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
    "# La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
    "\n",
    "TendenciaYmuchomas <- function(\n",
    "    dataset, cols, ventana = 6, tendencia = TRUE,\n",
    "    minimo = TRUE, maximo = TRUE, promedio = TRUE,\n",
    "    ratioavg = FALSE, ratiomax = FALSE) {\n",
    "  gc(verbose= FALSE)\n",
    "  # Esta es la cantidad de meses que utilizo para la historia\n",
    "  ventana_regresion <- ventana\n",
    "\n",
    "  last <- nrow(dataset)\n",
    "\n",
    "  # creo el vector_desde que indica cada ventana\n",
    "  # de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
    "  vector_ids <- dataset[ , numero_de_cliente ]\n",
    "\n",
    "  vector_desde <- seq(\n",
    "    -ventana_regresion + 2,\n",
    "    nrow(dataset) - ventana_regresion + 1\n",
    "  )\n",
    "\n",
    "  vector_desde[1:ventana_regresion] <- 1\n",
    "\n",
    "  for (i in 2:last) {\n",
    "    if (vector_ids[i - 1] != vector_ids[i]) {\n",
    "      vector_desde[i] <- i\n",
    "    }\n",
    "  }\n",
    "  for (i in 2:last) {\n",
    "    if (vector_desde[i] < vector_desde[i - 1]) {\n",
    "      vector_desde[i] <- vector_desde[i - 1]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  for (campo in cols) {\n",
    "    nueva_col <- fhistC(dataset[, get(campo)], vector_desde)\n",
    "\n",
    "    if (tendencia) {\n",
    "      dataset[, paste0(campo, \"_tend\", ventana) :=\n",
    "        nueva_col[(0 * last + 1):(1 * last)]]\n",
    "    }\n",
    "\n",
    "    if (minimo) {\n",
    "      dataset[, paste0(campo, \"_min\", ventana) :=\n",
    "        nueva_col[(1 * last + 1):(2 * last)]]\n",
    "    }\n",
    "\n",
    "    if (maximo) {\n",
    "      dataset[, paste0(campo, \"_max\", ventana) :=\n",
    "        nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "\n",
    "    if (promedio) {\n",
    "      dataset[, paste0(campo, \"_avg\", ventana) :=\n",
    "        nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratioavg) {\n",
    "      dataset[, paste0(campo, \"_ratioavg\", ventana) :=\n",
    "        get(campo) / nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratiomax) {\n",
    "      dataset[, paste0(campo, \"_ratiomax\", ventana) :=\n",
    "        get(campo) / nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:15:46 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering Historico\n",
    "# Creacion de LAGs\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "))\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "  dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "  dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros de Feature Engineering Historico de Tendencias\n",
    "PARAM$FE_hist$Tendencias$run <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ventana <- 6\n",
    "PARAM$FE_hist$Tendencias$tendencia <- TRUE\n",
    "PARAM$FE_hist$Tendencias$minimo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$maximo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$promedio <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ratioavg <- FALSE\n",
    "PARAM$FE_hist$Tendencias$ratiomax <- FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1178"
      ],
      "text/latex": [
       "1178"
      ],
      "text/markdown": [
       "1178"
      ],
      "text/plain": [
       "[1] 1178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:17:29 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aqui se agregan las tendencias de los ultimos 6 meses\n",
    "\n",
    "cols_lagueables <- intersect(cols_lagueables, colnames(dataset))\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "if( PARAM$FE_hist$Tendencias$run) {\n",
    "    TendenciaYmuchomas(dataset,\n",
    "    cols = cols_lagueables,\n",
    "    ventana = PARAM$FE_hist$Tendencias$ventana, # 6 meses de historia\n",
    "    tendencia = PARAM$FE_hist$Tendencias$tendencia,\n",
    "    minimo = PARAM$FE_hist$Tendencias$minimo,\n",
    "    maximo = PARAM$FE_hist$Tendencias$maximo,\n",
    "    promedio = PARAM$FE_hist$Tendencias$promedio,\n",
    "    ratioavg = PARAM$FE_hist$Tendencias$ratioavg,\n",
    "    ratiomax = PARAM$FE_hist$Tendencias$ratiomax\n",
    "  )\n",
    "}\n",
    "\n",
    "ncol(dataset)\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de la eficiencia --> media2/(desvio2+media2), tomando 6 meses moviles\n",
    "\n",
    "library(Rcpp)\n",
    "\n",
    "cppFunction('\n",
    "NumericVector eficienciaC(NumericVector pcolumna, IntegerVector pdesde) {\n",
    "  double valores[100];\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out(n);\n",
    "\n",
    "  for (int i = 0; i < n; i++) {\n",
    "    int libre = 0;\n",
    "    for (int j = pdesde[i]-1; j <= i; j++) {\n",
    "      if (j >= 0 && j < n) {\n",
    "        double a = pcolumna[j];\n",
    "        if (!R_IsNA(a)) {\n",
    "          valores[libre] = a;\n",
    "          libre++;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if (libre > 1) {\n",
    "      // Calcular promedio\n",
    "      double sum = 0;\n",
    "      for (int k = 0; k < libre; k++) sum += valores[k];\n",
    "      double mean = sum / libre;\n",
    "\n",
    "      // Calcular desviación estándar\n",
    "      double sumsq = 0;\n",
    "      for (int k = 0; k < libre; k++) sumsq += (valores[k] - mean) * (valores[k] - mean);\n",
    "      double sd = sqrt(sumsq / (libre - 1));\n",
    "\n",
    "      // Fórmula de eficiencia\n",
    "      out[i] = (mean * mean) / (mean * mean + sd * sd);\n",
    "    } else {\n",
    "      out[i] = NA_REAL;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return out;\n",
    "}\n",
    "')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1333"
      ],
      "text/latex": [
       "1333"
      ],
      "text/markdown": [
       "1333"
      ],
      "text/plain": [
       "[1] 1333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# columnas que tienen promedio de 3 meses\n",
    "cols_avg3 <- grep(\"_avg6$\", names(dataset), value = TRUE)\n",
    "\n",
    "# ventana de 3 meses\n",
    "ventana <- 6\n",
    "\n",
    "# generar vector_desde igual al usado en TendenciaYmuchomas\n",
    "vector_ids <- dataset[, numero_de_cliente]\n",
    "vector_desde <- seq(-ventana + 2, nrow(dataset) - ventana + 1)\n",
    "vector_desde[1:ventana] <- 1\n",
    "\n",
    "for (i in 2:nrow(dataset)) {\n",
    "  if (vector_ids[i - 1] != vector_ids[i]) vector_desde[i] <- i\n",
    "}\n",
    "for (i in 2:nrow(dataset)) {\n",
    "  if (vector_desde[i] < vector_desde[i - 1]) vector_desde[i] <- vector_desde[i - 1]\n",
    "}\n",
    "\n",
    "# aplicar eficiencia móvil de 3 meses\n",
    "for (campo in cols_avg3) {\n",
    "  nueva_col <- eficienciaC(dataset[[campo]], vector_desde)\n",
    "  dataset[, paste0(sub(\"_avg6\", \"\", campo), \"_eficiencia6\") := nueva_col]\n",
    "}\n",
    "ncol(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay modelado, no se hace optimizacion de hiperparametros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "## Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las decisiones que se toman para la construccion del modelo final son:\n",
    "* Los positvos son  POS={\"BAJA+1\", \"BAJA+2\"}, esta es una meticulosa decisión.\n",
    "* Se entrena en los treinta meses del intervalo [201901, 202104]\n",
    "* Se realiza undersampling al 5%\n",
    "* Se utilizan los hiperparámetros optimos encontrados en la Bayesian Optimization\n",
    "   * Se escala min_data_in_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### Final Training Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM$train_final$future <- c(202108)\n",
    "\n",
    "PARAM$train_final$training <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104, 202105, 202106\n",
    ")\n",
    "\n",
    "PARAM$train_final$undersampling <- 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se filtran los meses donde se entrena el modelo final\n",
    "dataset_train_final <- dataset[foto_mes %in% PARAM$train_final$training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:19:07 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# canaritos\n",
    "PARAM$train_final$lgbm$qcanaritos <- plocal$qcanaritos\n",
    "\n",
    "cols0 <- copy(colnames(dataset_train_final))\n",
    "filas <- nrow(dataset_train_final)\n",
    "\n",
    "if( PARAM$train_final$lgbm$qcanaritos > 0 ) {\n",
    "  for( i in seq(PARAM$train_final$lgbm$qcanaritos) ){\n",
    "    dataset_train_final[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "  }\n",
    "\n",
    "  # las columnas canaritos mandatoriamente van al comienzo del dataset\n",
    "  cols_canaritos <- copy( setdiff( colnames(dataset_train_final), cols0 ) )\n",
    "  setcolorder( dataset_train_final, c( cols_canaritos, cols0 ) )\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train_final[, azar := runif(nrow(dataset_train_final))]\n",
    "dataset_train_final[, training := 0L]\n",
    "\n",
    "dataset_train_final[\n",
    "  (azar <= PARAM$train_final$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "\n",
    "dataset_train_final[, azar:= NULL] # elimino la columna azar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train_final[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui SIEMPRE voy a hacer un semillerio, independientemente de si en la Bayesian Optimization calculé un semillerio en cada iteración.\n",
    "<br> Entreno un LightGBM para cada semilla,  y guardo el modelo dentro de la carpeta  **modelitos**\n",
    "<br> Intencionalmente en una primera etapá se generan los modelos y graban, y en una segunda etapa se leen eso modelos y se aplican a los datos del futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APO controla cuantas veces se repite el modelo, que se usa para promediar ganancias y reportar en la Pseudo Competencia algo razonable\n",
    "<br> El modelo puede ser un LightGBM simple (ksemillerio==1)  o un Ensemble Semillerio( ksemillerio > 1 )\n",
    "<br> Lamentablmente APO necesita utilizar muchas semillas, y eso demanda TIEMPO de corrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:19:09 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "PARAM$train_final$lgbm$param_completo <-  list(\n",
    "  boosting= \"gbdt\",\n",
    "  objective= \"binary\",\n",
    "  metric= \"custom\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE,\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_bin= 31L,\n",
    "  min_data_in_leaf= plocal$min_data_in_leaf,  #este ya es el valor default de LightGBM\n",
    "\n",
    "  num_iterations= 64L, # dejo libre la cantidad de arboles, zLightGBM se detiene solo\n",
    "  num_leaves= 9999L, # dejo libre la cantidad de hojas, zLightGBM sabe cuando no hacer un split\n",
    "  learning_rate= plocal$learning_rate,  # se lo deja en 1.0 para que si el score esta por debajo de gradient_bound no se lo escale\n",
    "    \n",
    "  feature_fraction= 0.50, # un valor equilibrado, habra que probar alternativas ...\n",
    "    \n",
    "  canaritos= PARAM$train_final$lgbm$qcanaritos, # fundamental en zLightGBM, aqui esta el control del overfitting\n",
    "  gradient_bound= plocal$gradient_bound   # default de zLightGBM\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semillerio Final\n",
    "PARAM$train_final$APO <- plocal$APO\n",
    "PARAM$train_final$ksemillerio  <- plocal$ksemillerio\n",
    "\n",
    "PARAM$train_final$cortes <- c(8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach(\"package:lightgbm\", unload= TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: zlightgbm\n",
      "\n",
      "Registered S3 methods overwritten by 'zlightgbm':\n",
      "  method                 from    \n",
      "  dimnames<-.lgb.Dataset lightgbm\n",
      "  dim.lgb.Dataset        lightgbm\n",
      "  dimnames.lgb.Dataset   lightgbm\n",
      "  predict.lgb.Booster    lightgbm\n",
      "  print.lgb.Booster      lightgbm\n",
      "  summary.lgb.Booster    lightgbm\n",
      "\n",
      "\n",
      "Attaching package: ‘zlightgbm’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:lightgbm’:\n",
      "\n",
      "    get_field, getLGBMthreads, lgb.configure_fast_predict,\n",
      "    lgb.convert_with_rules, lgb.cv, lgb.Dataset, lgb.Dataset.construct,\n",
      "    lgb.Dataset.create.valid, lgb.Dataset.save,\n",
      "    lgb.Dataset.set.categorical, lgb.Dataset.set.reference,\n",
      "    lgb.drop_serialized, lgb.dump, lgb.get.eval.result, lgb.importance,\n",
      "    lgb.interprete, lgb.load, lgb.make_serializable, lgb.model.dt.tree,\n",
      "    lgb.plot.importance, lgb.plot.interpretation, lgb.restore_handle,\n",
      "    lgb.save, lgb.slice.Dataset, lgb.train, lightgbm, set_field,\n",
      "    setLGBMthreads\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if( !require(\"zlightgbm\") ) install.packages(\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/zlightgbm_4.6.0.99.tar.gz\", repos= NULL, type= \"source\")\n",
    "require(\"zlightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: primes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(!require(\"primes\")) install.packages(\"primes\")\n",
    "require(\"primes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>240881</li><li>812527</li><li>303187</li><li>805843</li><li>360457</li><li>560437</li><li>160507</li><li>653503</li><li>948707</li><li>469811</li><li>184843</li><li>542149</li><li>266417</li><li>568609</li><li>636721</li><li>127709</li><li>587527</li><li>510047</li><li>588521</li><li>694079</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 240881\n",
       "\\item 812527\n",
       "\\item 303187\n",
       "\\item 805843\n",
       "\\item 360457\n",
       "\\item 560437\n",
       "\\item 160507\n",
       "\\item 653503\n",
       "\\item 948707\n",
       "\\item 469811\n",
       "\\item 184843\n",
       "\\item 542149\n",
       "\\item 266417\n",
       "\\item 568609\n",
       "\\item 636721\n",
       "\\item 127709\n",
       "\\item 587527\n",
       "\\item 510047\n",
       "\\item 588521\n",
       "\\item 694079\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 240881\n",
       "2. 812527\n",
       "3. 303187\n",
       "4. 805843\n",
       "5. 360457\n",
       "6. 560437\n",
       "7. 160507\n",
       "8. 653503\n",
       "9. 948707\n",
       "10. 469811\n",
       "11. 184843\n",
       "12. 542149\n",
       "13. 266417\n",
       "14. 568609\n",
       "15. 636721\n",
       "16. 127709\n",
       "17. 587527\n",
       "18. 510047\n",
       "19. 588521\n",
       "20. 694079\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 240881 812527 303187 805843 360457 560437 160507 653503 948707 469811\n",
       "[11] 184843 542149 266417 568609 636721 127709 587527 510047 588521 694079"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "primos <- generate_primes(min = 100000, max = 1000000)\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "PARAM$train_final$semillas <- sample(primos)[seq( PARAM$train_final$APO*PARAM$train_final$ksemillerio )]\n",
    "PARAM$train_final$semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train_final),\n",
    "  c( \"clase_ternaria\", \"clase01\", \"training\", \"azar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filas 473830 columnas 1337 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 19:19:30 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en formato LightGBM\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 20:10:03 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# genero los modelitos\n",
    "dir.create( \"modelitos\", showWarnings= FALSE)\n",
    "\n",
    "param_completo <- copy( PARAM$train_final$lgbm$param_completo)\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( !file.exists( arch_modelo ) )\n",
    "  {\n",
    "    param_completo$seed <- sem\n",
    "\n",
    "    modelito <- lgb.train(\n",
    "      data= dtrain_final,\n",
    "      param= param_completo\n",
    "    )\n",
    "\n",
    "    lgb.save( modelito, filename= arch_modelo)\n",
    "    rm(modelito)\n",
    "    gc()\n",
    "  }\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el predict() del modelo en los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfuture <- dataset[foto_mes %in% PARAM$train_final$future ]\n",
    "\n",
    "cols0 <- copy(colnames(dfuture))\n",
    "filas <- nrow(dfuture)\n",
    "\n",
    "if( PARAM$train_final$lgbm$qcanaritos > 0 ) {\n",
    "  for( i in seq(PARAM$train_final$lgbm$qcanaritos) ){\n",
    "    dfuture[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "  }\n",
    "\n",
    "  # las columnas canaritos mandatoriamente van al comienzo del dataset\n",
    "  cols_canaritos <- copy( setdiff( colnames(dfuture), cols0 ) )\n",
    "  setcolorder( dfuture, c( cols_canaritos, cols0 ) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset de future, donde en este caso estoy haciendo testing\n",
    "\n",
    "mfuture <- data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    "\n",
    "#dfuture[, ganancia := ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mganancias <- matrix( nrow=PARAM$train_final$APO, ncol= length(PARAM$train_final$cortes) )\n",
    "\n",
    "# if( file.exists(\"prediccion.txt\") )\n",
    "#   file.remove(\"prediccion.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 20:12:20 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aplico el modelo a los datos del future\n",
    "\n",
    "vpred_acum <- rep(0.0, nrow(dfuture))\n",
    "qacumulados <- 0\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( file.exists( arch_modelo ) )\n",
    "  {\n",
    "    modelo_final <- lgb.load(arch_modelo) # leo del disco\n",
    "    #hago el predict() y acumulo\n",
    "    vpred_acum <- vpred_acum + predict(modelo_final, mfuture)\n",
    "    qacumulados <- qacumulados + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "vpred_acum <- vpred_acum / qacumulados  # paso a probabildiad\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabla de prediccion, puede ser util para futuros ensembles\n",
    "#  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := vpred_acum ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # genero archivos con los  \"envios\" mejores\n",
    "# dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "\n",
    "# tb_prediccion <- fread(\"prediccion.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [],
   "source": [
    "dir.create(\"kaggle\", showWarnings = FALSE)\n",
    "\n",
    "# Ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "# Recorro los valores deseados\n",
    "for (envios in seq(9500, 12000, by = 500)) \n",
    "{\n",
    "  tb_prediccion[, Predicted := 0L]              \n",
    "  tb_prediccion[1:envios, Predicted := 1L]      \n",
    "  \n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "  \n",
    "  fwrite(tb_prediccion[, .(numero_de_cliente, Predicted)],\n",
    "         file = archivo_kaggle,\n",
    "         sep = \",\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subida a Pseudo Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui viene la verdadera magia de  APO = A Prueba Overfiteres\n",
    "<br>Se sube un submit a la Pseudo Competencia Kaggle cuya ganancia coincide casi exactamente con la ganancia MEDIA , promediada  APO veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colmedias <- colMeans( mganancias, na.rm=TRUE )\n",
    "# mcorte_mejor <- max(colmedias, na.rm=TRUE)\n",
    "# icorte_mejor <- which.max( colmedias )\n",
    "# corte_mejor <- PARAM$train_final$cortes[icorte_mejor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl <- as.data.table( as.list( colmedias ) )\n",
    "# colnames(tbl) <- paste0( \"e\", PARAM$train_final$cortes )\n",
    "# tbl[, experimento := PARAM$experimento ]\n",
    "\n",
    "# exp_gral <- \"/content/buckets/b1/exp/apo-gral\"\n",
    "# dir.create(exp_gral, showWarnings=FALSE)\n",
    "# fwrite( tbl,\n",
    "#   file= paste0( exp_gral, \"/tb_experimentos.txt\"),\n",
    "#   sep= \"\\t\",\n",
    "#   append= TRUE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colnames( mganancias ) <- paste0( \"e\", PARAM$train_final$cortes )\n",
    "# tbl_local <- as.data.table( mganancias )\n",
    "\n",
    "# fwrite( tbl_local,\n",
    "#   file= \"tb_apo.txt\",\n",
    "#   sep= \"\\t\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icerca <- which.min(  abs( tb_prediccion$gan_acum - mcorte_mejor ) )\n",
    "# vmodelo <- tb_prediccion[ icerca, meta_modelo ]\n",
    "# tb_pred <- tb_prediccion[meta_modelo==vmodelo]\n",
    "\n",
    "# mcorte_mejor\n",
    "# icerca\n",
    "# tb_prediccion[ icerca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icerca <- which.min(  abs( tb_pred$gan_acum - mcorte_mejor ) )\n",
    "# icerca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icerca <- which.min(  abs( tb_prediccion$gan_acum - mcorte_mejor ) )\n",
    "# vmodelo <- tb_prediccion[ icerca, meta_modelo ]\n",
    "# tb_pred <- tb_prediccion[meta_modelo==vmodelo]\n",
    "\n",
    "# icerca <- which.min(  abs( tb_pred$gan_acum - mcorte_mejor ) )\n",
    "# tb_pred[, Predicted := 0L] # seteo inicial a 0\n",
    "# tb_pred[1:icerca, Predicted := 1L] # marco los primeros\n",
    "\n",
    "# archivo_pseudo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\",  icerca, \".csv\")\n",
    "\n",
    "# # grabo el archivo\n",
    "# fwrite(tb_pred[, list(numero_de_cliente, Predicted)],\n",
    "#   file= archivo_pseudo_kaggle,\n",
    "#   sep= \",\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # la subida a Kaggle\n",
    "# comando <- \"kaggle competitions submit\"\n",
    "# competencia <- \"-c  test-202106\"\n",
    "# arch <- paste( \"-f\", archivo_pseudo_kaggle)\n",
    "# mensaje <-  paste0( \"-m 'exp=\", PARAM$experimento,\n",
    "#   \"  \", paste(names(plocal), plocal, sep= \"=\", collapse= \";\" ),\n",
    "#   \" envios=\", icorte_mejor,\"'\")\n",
    "\n",
    "                    \n",
    "# linea <- paste( comando, competencia, arch, mensaje)\n",
    "# salida <- system(linea, intern=TRUE)\n",
    "# cat(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-15 20:12:23 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
